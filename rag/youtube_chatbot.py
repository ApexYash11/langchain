# -*- coding: utf-8 -*-
"""youtube chatbot.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aNenk6o-GOgkzM8zjPP3WIANENhWdH6K
"""

import os
os.environ["GEMini_api_key"]="AIz"

!pip install -q youtube-transcript-api langchain-community langchain-openai langchain-google-genai \
               faiss-cpu tiktoken python-dotenv

from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_google_genai import GoogleGenerativeAIEmbeddings

from langchain_community.vectorstores import FAISS
from langchain_core.prompts import PromptTemplate

"""Indexing

"""

video_id = "7ARBJQn6QkM"

try:
    fetched_transcript = YouTubeTranscriptApi().fetch(video_id, languages=['en'])
    transcript_list = fetched_transcript.to_raw_data()
    transcript = " ".join(chunk["text"] for chunk in transcript_list)
    print(transcript)

except TranscriptsDisabled:
    print("No captions available for this video.")
except Exception as e:
    print(f"An error occurred: {e}")

transcript_list

"""TEXT SPILTTER PART 1-B"""

spiltter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)
chunks=spiltter.create_documents([transcript])

len(chunks)

chunks[68]

"""STEP 1-C (EMBEDDING AND STORINGIN IN VECTOR)"""

!pip install langchain-huggingface

from langchain_community.vectorstores import FAISS
from langchain_huggingface import HuggingFaceEmbeddings

# Use free Hugging Face embeddings - no quotas
embeddings = HuggingFaceEmbeddings(
    model_name="sentence-transformers/all-MiniLM-L6-v2"
)

vector_store = FAISS.from_documents(chunks, embeddings)
print("âœ… Vector store created successfully with Hugging Face embeddings!")

vector_store.index_to_docstore_id

vector_store.get_by_ids(["dc8c9463-83c0-4c16-bb87-2a2390bbfa82"])

"""step 2 _RETERIVAL

"""

retriever=vector_store.as_retriever(search_type='similarity',search_kwargs={"k":4})

retriever

retriever.invoke("what is the meaning of life")

"""STEP3 AUGEMTATION"""

from langchain_google_genai import ChatGoogleGenerativeAI
import os

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    temperature=0.3,
    google_api_key=os.environ.get("GEMini_api_key")
)

!pip install -q langchain-google-genai google-generativeai

from langchain_core.prompts import PromptTemplate

propmt=PromptTemplate(
    template="""
    you are a helful assitant
    answer only from the provided transcript context
    if the context is insufficent, just say you dont know.

    {context}

    question: {question}
    """,
    input_variables=["context","question"]
)

question="is the topic of nuclear fusion discussed in this video? if yes then what was discussed"
retrieved_docs=retriever.invoke(question)

retrieved_docs

context_text= "\n\n".join(doc.page_content for doc in retrieved_docs)

context_text

final_propmt=propmt.invoke(input={"context": context_text, "question": question})

final_propmt

"""STEP: 4 Genration"""

answer=llm.invoke(final_propmt)
print(answer.content)

"""Building chains

"""

from langchain_core.runnables import RunnableParallel, RunnablePassthrough,RunnableLambda
from langchain_core.output_parsers import StrOutputParser

from annotated_types import doc
def format_docs(retrieved_docs):
  context_text="\n\n" .join(doc.page_content for doc in retrieved_docs)
  return context_text

parallel_chain=RunnableParallel({
    'context': retriever | RunnableLambda(format_docs),
    'question':RunnablePassthrough()
})

parallel_chain.invoke("what is the meaning of life")

parser=StrOutputParser()

Main_chain=parallel_chain | propmt | llm | parser

Main_chain.invoke("can you summarise this viedo")

